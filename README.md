# BinaryClassifier-LogReg

This project demonstrates a practical application of logistic regression to binary classification, using a simplified version of the MNIST dataset focusing on two digits: 0 and 1. The core objective was to implement logistic regression and the gradient descent optimization algorithm from scratch in Python, providing a hands-on experience with fundamental machine learning concepts.

# Project Highlights

    - Logistic Regression from Scratch: Developed a logistic regression model without relying on high-level machine learning libraries, offering a deep dive into the algorithm's mechanics.
    - Binary Classification on MNIST: Applied the model to a binary classification task, distinguishing between two specific digits from the MNIST dataset, to understand model performance and limitations.
    - Custom Testing Interface: Included an interactive interface for testing the model against user-drawn images, enhancing the learning experience by directly observing the model's predictions.

# Performance
    - The logistic regression model achieved an impressive accuracy of over 99% on the test data within just a few dozen training iterations. This performance highlights the model's efficiency and the effectiveness of the gradient descent optimization in quickly converging to a high level of accuracy.

# Learning Outcomes

    - Gained proficiency in implementing and debugging machine learning algorithms using Python.
    - Developed an understanding of the gradient descent optimization technique and its application in training logistic regression models.
    - Enhanced problem-solving skills through the development of a user interface for model testing.

This project served as a valuable learning experience in machine learning fundamentals, providing a solid foundation for future exploration in the field.

## Authors

    Wajdi Maatouk

## Acknowledgments

    Inspiration and guidance from the Neural Networks and Deep Learning course by DeepLearning.AI, available on Coursera. 
    MNIST dataset provided by Yann LeCun, Corinna Cortes, and Christopher J.C. Burges.
